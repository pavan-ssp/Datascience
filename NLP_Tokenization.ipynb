{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### NLP [Natural Language Processing]\n",
        "\n",
        "Here we use NLTK Library To convert a paragraph into sentences and words from the paragragh for further processing."
      ],
      "metadata": {
        "id": "WeoS2_YADzZi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6F9i9T1Dp4M",
        "outputId": "32b5fd5a-850a-4d56-bbfd-67d29879fe00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> \n",
            "Downloader> \n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> \n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download()\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paragragh=\"\"\"\n",
        "Natural Language Processing (NLP) is a field of artificial intelligence that focuses on the interaction between computers and human languages.\n",
        "It involves various tasks, such as text analysis, sentiment analysis, and machine translation.\n",
        "One of the most common NLP tasks is tokenization, which is the process of splitting text into smaller units.\n",
        "These units can be words or sentences. In tokenization, the text is divided into sentences using sentence tokenization,\n",
        "and each sentence is further broken down into individual words using word tokenization.\n",
        "Tokenization is a crucial step for many other NLP applications, including text classification and named entity recognition.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "3S1qvPzlEQSS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences=nltk.sent_tokenize(paragragh)\n",
        "words=nltk.word_tokenize(paragragh)"
      ],
      "metadata": {
        "id": "lLmCClqIEv9j"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23TOKbl0E4vF",
        "outputId": "839b6c35-1f19-4c62-9757-01ce614e1a47"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\nNatural Language Processing (NLP) is a field of artificial intelligence that focuses on the interaction between computers and human languages.',\n",
              " 'It involves various tasks, such as text analysis, sentiment analysis, and machine translation.',\n",
              " 'One of the most common NLP tasks is tokenization, which is the process of splitting text into smaller units.',\n",
              " 'These units can be words or sentences.',\n",
              " 'In tokenization, the text is divided into sentences using sentence tokenization, \\nand each sentence is further broken down into individual words using word tokenization.',\n",
              " 'Tokenization is a crucial step for many other NLP applications, including text classification and named entity recognition.']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nGJPsTZFJg6",
        "outputId": "a167ddef-2d6f-49ab-c3e8-8a0260401239"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Natural',\n",
              " 'Language',\n",
              " 'Processing',\n",
              " '(',\n",
              " 'NLP',\n",
              " ')',\n",
              " 'is',\n",
              " 'a',\n",
              " 'field',\n",
              " 'of',\n",
              " 'artificial',\n",
              " 'intelligence',\n",
              " 'that',\n",
              " 'focuses',\n",
              " 'on',\n",
              " 'the',\n",
              " 'interaction',\n",
              " 'between',\n",
              " 'computers',\n",
              " 'and',\n",
              " 'human',\n",
              " 'languages',\n",
              " '.',\n",
              " 'It',\n",
              " 'involves',\n",
              " 'various',\n",
              " 'tasks',\n",
              " ',',\n",
              " 'such',\n",
              " 'as',\n",
              " 'text',\n",
              " 'analysis',\n",
              " ',',\n",
              " 'sentiment',\n",
              " 'analysis',\n",
              " ',',\n",
              " 'and',\n",
              " 'machine',\n",
              " 'translation',\n",
              " '.',\n",
              " 'One',\n",
              " 'of',\n",
              " 'the',\n",
              " 'most',\n",
              " 'common',\n",
              " 'NLP',\n",
              " 'tasks',\n",
              " 'is',\n",
              " 'tokenization',\n",
              " ',',\n",
              " 'which',\n",
              " 'is',\n",
              " 'the',\n",
              " 'process',\n",
              " 'of',\n",
              " 'splitting',\n",
              " 'text',\n",
              " 'into',\n",
              " 'smaller',\n",
              " 'units',\n",
              " '.',\n",
              " 'These',\n",
              " 'units',\n",
              " 'can',\n",
              " 'be',\n",
              " 'words',\n",
              " 'or',\n",
              " 'sentences',\n",
              " '.',\n",
              " 'In',\n",
              " 'tokenization',\n",
              " ',',\n",
              " 'the',\n",
              " 'text',\n",
              " 'is',\n",
              " 'divided',\n",
              " 'into',\n",
              " 'sentences',\n",
              " 'using',\n",
              " 'sentence',\n",
              " 'tokenization',\n",
              " ',',\n",
              " 'and',\n",
              " 'each',\n",
              " 'sentence',\n",
              " 'is',\n",
              " 'further',\n",
              " 'broken',\n",
              " 'down',\n",
              " 'into',\n",
              " 'individual',\n",
              " 'words',\n",
              " 'using',\n",
              " 'word',\n",
              " 'tokenization',\n",
              " '.',\n",
              " 'Tokenization',\n",
              " 'is',\n",
              " 'a',\n",
              " 'crucial',\n",
              " 'step',\n",
              " 'for',\n",
              " 'many',\n",
              " 'other',\n",
              " 'NLP',\n",
              " 'applications',\n",
              " ',',\n",
              " 'including',\n",
              " 'text',\n",
              " 'classification',\n",
              " 'and',\n",
              " 'named',\n",
              " 'entity',\n",
              " 'recognition',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x_ybKUIrFNLd"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}